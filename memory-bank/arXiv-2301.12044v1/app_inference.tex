\section{Inference}\label{sec:inference}
This paper does not develop any novel approaches to statistical inference in matched pairs design. However, in this section we outline two ways that could be used to test hypotheses and construct confidence intervals.

\subsection{Approximation by Student's $t$-distribution}
We can use the approach from Section~5.2 of \citet{chen2022robust} which uses an approximation by Student's $t$-distribution to recover a confidence level for $\theta$.

%. For each supergeo pair $(G_{k,+}, G_{k,-})$ and a value of $\theta$ we can compute $\epsilon_k(\theta) := (R_{G_{k,+}} - \theta S_{G_{k,+}}) -  (R_{G_{k,-}} - \theta S_{G_{k,-}})$ if $G_{k,+}$ is in treatment and we flip the sign otherwise. We approximate the distribution of these errors $\{\epsilon_1(\theta),\dots, \epsilon_K(\theta)\}$ (after normalization) with a Student's $t$-distribution., and we compute the 80\% confidence intervals by computing the 80\% quantile of this distribution. 
%its error $\epsilon_k(\hat{\theta}) := (R_{G_{k,+}} - \hat{\theta} S_{G_{k,+}}) -  (R_{G_{k,-}} - \hat{\theta} S_{G_{k,-}})$ if $G_{k,+}$ is in treatment and we flip the sign otherwise. We approximate the distribution of the errors $\{\epsilon_1(\hat{\theta}),\dots, \epsilon_K(\hat{\theta})\}$ (after normalization) with a Student's $t$-distribution., and we compute the 80\% confidence intervals by computing the 80\% quantile of this distribution. 

%We then compute the coverage of the confidence interval which is defined as the percentage of the estimates that fall into the computed confidence intervals. In Table~\ref{tab:sync_40_geo} we observe that the estimation of the confidence interval can become less accurate when there are fewer supergeo pairs. This is more evident when using the empirical estimator, and less so when using the trimmed match estimator since many pairs are trimmed.
%We will compute the coverage of nominally 80\% confidence intervals, where the coverage is defined as the percentage of the estimates that fall into the computed confidence intervals. 
%Furthermore, the estimation of the confidence interval can become less accurate when there are fewer supergeo pairs. This justifies our choice of a small subset size in $\{3,4\}$.

\subsection{Permutation-based inference}
Alternatively, we can test the sharp null hypothesis of zero treatment effects across all geos. Under this null, the treatment assignment does not matter and the estimate $\hat{\theta}$ is randomly drawn from the distribution $\{\hat{\theta}_a\}_{a\in\mathcal{A}}$, where $\mathcal{A}$ is the set of all possible treatment assignments. This distribution can be approximated---under the null hypothesis---by repeatedly re-drawing different treatment assignments and computing the corresponding $\hat{\theta}_a$. The null hypothesis is then rejected if the original estimate, $\hat{\theta}$, falls beyond some quantiles (e.g.~10\% or 90\%) of the constructed distribution. 

These tests can also be inverted to produce a confidence interval, but that would require additional assumptions. For instance, for each candidate value $\theta^{*}$ and a null hypothesis $H_0\colon\theta=\theta^{*}$ we could first remove the effect of the treatment from the responses of the treated units (assuming that the null hypothesis holds and $\theta^{*}$ is indeed the true value of $\theta$). Then, we would re-draw the treatment assignment, $a\in\mathcal{A}$, inject the effects (still assuming $\theta=\theta^{*}$) into the responses of the newly treated units, and re-estimate $\hat{\theta}_a$. We would repeat this multiple times to construct the distribution and test the null hypothesis in the same way as we did for $\theta^{*}=0$. We would construct a confidence interval for $\theta$ as the set of all $\theta^{*}$ for which the corresponding $H_0$'s are not rejected at the desired level of statistical significance.