\section{Introduction}\label{intro}
With online advertising revenue in the US amounting to almost 200 billion dollars in 2021 \citep{iab_report_2021}, it is both theoretically and practically important to understand advertising effectiveness. For instance, researchers may want to know how much additional sales revenue does an additional dollar spend on advertising generate? %\Nick{Following the example of one of Aiyou's earlier papers, found a reference that has a number for the size of ``online'' advertising industry. I'm curious if we can either find a similar number for ``all'' advertising or if it's okay to leave it as is, but continue talking in a bit more general way about advertising.} 
Ideally, such questions would be addressed via
the ``gold standard'' of causal inference---randomized experiments or A/B tests as they are often called in applied settings.  
%\Cliff{I replaced this sentence by the one above: To establish a causal relationship between advertising spend and sales revenue (or an alternative outcome variable), a researcher would be remiss not to contemplate utilizing the ``gold standard'' of causal inference---randomized experiments or A/B tests as they are often called in applied industrial settings.}

When many distinct units are available to experiment on and the estimand of interest is the \emph{average treatment effect} (ATE), simple randomized experiments may provide precise and intuitive results. Unfortunately, such experiments are not always available or, even when they are, may not be adequate for the question at hand. For instance, if interference between the experimental units---a situation in which the treatment status of one unit affects the outcomes of some other units---is not negligible, the researchers may decide to combine units into larger groups (or clusters) if they have reasons to believe that interference at the group level is less of a concern. In other cases, institutional constraints or privacy concerns may prevent the researchers from assigning the treatment at a more granular level. Neither of these concerns are foreign to the studies of advertising effectiveness \citep{coey2016people,vaver2011measuring}.   %\Cliff{Needs a citation}\Aiyou{Added two references} 
For example, product information learned from an ad by one person can be easily propagated to another person who has not seen the ad introducing interference. Different variations of television advertising are often assigned at the designated market area (DMA) level limiting the number of experimental units to only 210 DMAs existing in the US.\footnote{\url{https://markets.nielsen.com/us/en/contact-us/intl-campaigns/dma-maps/}} Moreover, targeted advertising is an important subject of current academic and public discourse with an increasing number of studies conducted at geographic---instead of more granular---levels \citep[Google Ads geo targets,\footnote{\url{https://developers.google.com/google-ads/api/reference/data/geotargets}}][]{rolnick2019randomized}. 
%\Nick{Not sure if we want to get into this, but might be a good idea to illustrate that the potential concerns mentioned earlier are relevant to iROAS estimation. Perhaps we could come up with a good non-controversial reference here.}\Shunhua{I vote for not going into more details here. This paragraph already looks convincing to me.}\Nick{The current sentence (after ``Moreover'') reads weird to me without any references. If we don't want to cite anything, I would just remove this sentence.}\Bicheng{Why not we just refer the GraphCut on Geo Adversiting paper and its reference for another example?}\Aiyou{It looks a good idea to add some references, e.g. Google Ads website on geo targeting? https://developers.google.com/google-ads/api/reference/data/geotargets} 
These considerations may not only limit the sample size, but also lead to experimental units that vary substantially along observed---and potentially unobserved---characteristics, thereby preventing the researchers from relying on large-sample properties alone and forcing them to make additional assumptions.

We are primarily motivated by evaluating advertising effectiveness using geographic experiments. However, these issues---relatively small sample size and heterogeneity of experimental units---may come up in other settings. Regardless of the setting, there are two general ways to improve the statistical properties of experimental results---by changing the allocation of units to treatment and control (\emph{experimental design}) or by changing the approach to estimating the quantity of interest (\emph{post-experimental analysis}). One common approach to experimental design is to find disjoint pairs of comparable units and randomize the treatment within each pair---the so called \emph{matched pairs design} \citep{imbens2015causal}. This experimental design has several advantages:  %\Shunhua{Change this sentence to ``This \emph{paired matching design} has several advantages''? In later sections I'm referring this approach as the paired matching design, and I think here is a good place to introduce this name.}\Nick{Done.}
(i) it allows---at least to some degree---balancing the control and treatment groups with respect to the observed unit-level covariates, (ii) the treatment effects can be estimated separately for each pair which may be particularly useful when the effects are heterogeneous, (iii) randomizing the treatment within each pair allows rigorous statistical inference (e.g.~permutation-based tests). Optimal matched pairs can be designed by solving a minimum-weight matching problem  %\Shunhua{Change this to minimum weight matching problem? Since that's the more common name in CS.} 
\citep[see, for example, Chapter~12 of][]{rosenbaum2020design} which can be done in polynomial time \citep{edmonds1965maximum}.\footnote{See \citet{stuart2010matching}, \citet{rosenbaum2020design} and \citet{pashley2021insights} for additional references to various general-purpose matching methods.}
%\Cliff{Should say here something like.  If the weight is defined by some similarity metric between two units -- for instance, ias the distance in the covariate space-- then the problem of finding the best pairing is a (non-bipartite) minimum weight matching problem.  This problem can be solved in polynomial time, e.g.  \citep{edmonds1965maximum} ... say more about statistics literature} In practice, the classical minimum-weight matching (MWM) algorithm, where the weight is defined by some similarity metric between two units---for instance, as the distance in the covariate space---can generate the design efficiently \citep{edmonds1965maximum}. \Nick{We need more references to applied statistical research.} 
%\Bicheng{I found this interesting literature: \href{https://journals.sagepub.com/doi/pdf/10.3102/1076998620946272}{Insights on Variance Estimation for Blocked and Matched Pairs Designs}: 
%\begin{quote} much of the prior work on randomized experiments has focused on two forms of blocking: blocking where there are several treated and control units in each block and blocking where there is exactly one treated and one control unit in each block (matched pairs). This literature, for the most part, has a gap: It has not extensively treated the cases where researchers have generated groups of varying size but where there is still only one treated and/or one control in some of the blocks, which we call the “hybrid design.” \end{quote} there are lots of literatures cited there as well.}\Nick{Added a reference.}

Unfortunately, it is not always possible to construct pairs of units that are sufficiently similar. It is not uncommon in applications to have pairs of units that are so different from each other that it is better to exclude some of them from the experiment completely in order to make the estimates more precise. This can be done either at the design phase \citep{chen2021trimmed} or during post analysis \citep{chen2022robust}. However, such ``trimming'' reduces the sample size and, perhaps more importantly, makes the resulting sample potentially different from the original population in terms of the average treatment effect if the effects are heterogeneous across units. Moreover, excluding pairs of units from the experiment may require stopping advertising in those units for the duration of the experiment. This may lead to a drop in sales revenue which otherwise could have been avoided.\footnote{We discuss the difference between ``trimming'' in the design and post-experimental analysis phases in a bit more detail in Section~\ref{sec:eval}.}%\Shunhua{I think we need to make it clear whether we are referring to trimmed match as an experimental design or a post-analysis tool here. We could add a footnote to make it clear that in the original paper trimmed match has both parts, but we consider them separately.}\Nick{I think it's fine in the current form for the introduction, but we should make it clear further on. Having said that, I'm open to suggestions on how to reword this.}\Cliff{Need to make clear that we want to keep all the data}\Aiyou{Good point. Tried to clarify it as above}\Nick{Added a footnote.}

\paragraph{Supergeo design.} To combat the issue of poor matches without sacrificing the data, we introduce a generalized matching problem in which each pair is a pair of ``superunits'' with each superunit being a sum of several original units. Conceptually, this extends the classical matched pairs to matched superunit-pairs.\footnote{The notion of ``superunit'' may not apply to all settings as the covariates and/or response variables may not be additive. For example, in medical science, it may not be meaningful to pair a group of two patients to another group of three patients. However, other aggregation approaches---besides the simple summation---may be considered depending on the application.} Since our primary motivation for this paper is geographic experiments where each unit is a DMA, in the remainder of the paper we use \emph{geo} and \emph{supergeo} as synonyms for unit and superunit respectively. We use the term \emph{supergeo design} to refer to the proposed methodology.

Finding the optimal supergeo design is closely related to the minimum-weight matching problem over the hyper-graph \citep{keevash2014geometric}. What differentiates our paper from previous algorithmic work is the fact that achieving good matches is not the end goal, but rather an approach to improving the statistical properties of the experimental results. Subsequently, we evaluate the proposed methodology as an experimental design tool.

We show that supergeo design can improve the precision of the average treatment effect estimates when compared to standard matched pairs design. %\Aiyou{Do we compare with simple randomized designs? If so, we need to add it back} %\Nick{Ideally, here we would add "and Trimmed Match Design" or whatever is the methodology that we consider for trimming some pairs before the experiment. I'll work on that.}
Moreover, it can substantially outperform the alternatives that require excluding some of the geos from the experiment when the treatment effects are heterogeneous since those alternative designs may lead to a subpopulation with a different average treatment effect compared to the original sample. 

Although further generalizations \citep[for example, in the spirit of the synthetic-control literature,][]{abadie2010synthetic} are possible, we currently assume that when the units are aggregated, the covariates used for matching are added up. For instance, this is appropriate when the covariate of interest is the total sales within a geo and we are willing to assume that as long as the time series of past sales data are matched well, the units should respond to treatment similarly.%\Aiyou{Is the point to say that if time series of past sales are matched well, their future sales would be comparable too if no treatment intervention would be applied?}\Nick{Yes, but also that if treated each of them would have a similar outcome under treatment.}

\paragraph{Contributions.} The main contributions of the paper are as follows:
\begin{itemize}
\item We propose a novel experimental design approach---supergeo design---that improves the balancing properties of matched pairs design. %\Shunhua{Should we use "matched pairs design" or "paired matching design"? Let's be consistent.}\Aiyou{Google search of 'paired matching design' leads to 'matched pairs design':) https://screenshot.googleplex.com/m7QWNJoGfv3HVk5. So revised.}\Shunhua{Thanks.}
\item We show that supergeo design can be particularly effective when the underlying treatment effects are heterogeneous since it allows achieving good treatment-control balance without excluding geos which would normally lead to poorly matched pairs.
%some of the poorly matched pairs from the experiment and/or analysis.
\item While this generalized matching problem is NP-hard, we propose an approach utilizing mixed-integer programming (MIP) that  solves the problem in practically important settings with hundreds of experimental units (representing geographic regions).
\item We validate the effectiveness of the proposed design using real advertising data.
\end{itemize}

%\Shunhua{We could also consider adding some bullet points here to summarize our contributions, as what is usually done in ICML/Neurips papers.} \Bicheng{+1, it is very common in these conference.}\Cliff{+1}

\paragraph{Structure of the paper.} We start by introducing a theoretical framework that allows us to discuss the statistical properties of alternative experimental design and analysis procedures. We then describe the methodology used for solving the supergeo matching problem. The empirical results section of the paper compares supergeo design to the matched pairs design. We also compare supergeo design to \emph{trimmed match estimator} \citep{chen2022robust} which is an analysis---rather than design---procedure and discuss the way in which supergeo design and trimmed match can be combined.%\footnote{In Section~\ref{sec:eval} we go into more detail on why this comparison is performed.}